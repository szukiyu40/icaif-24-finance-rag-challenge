{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# --------------------------------------\n",
    "# Import required libraries for document retrieval, reranking, and logging setup.\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "import datetime\n",
    "# link a path to ../financerag\n",
    "import os\n",
    "\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder\n",
    "from financerag.tasks import FinDER, FinQABench, FinanceBench, TATQA, FinQA, ConvFinQA, MultiHiertt\n",
    "\n",
    "import os  # Importing os to handle directory and file paths\n",
    "\n",
    "# Setup basic logging configuration to show info level messages.\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: /home/ec2-user/FinanceRAG/notebook/fine_tuned_sentence_transformer_e5-large-v2/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\ntorch.cuda.empty_cache()\\nencoder_model = SentenceTransformerEncoder(\\n    model_name_or_path=\\'Linq-AI-Research/Linq-Embed-Mistral\\',\\n    #model_name_or_path=\\'ProsusAI/finbert\\',\\n    query_prompt=\\'query: \\',\\n    #query_prompt = \"financial question about the company\\'s financial status: \",\\n    doc_prompt=\\'passage: \\',\\n    #doc_prompt = \\'inquiry about financial metrics and performance: \\'\\n)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Initialize DenseRetriever model\n",
    "# -------------------------------------\n",
    "# Initialize the retrieval model using SentenceTransformers. This model will be responsible\n",
    "# for encoding both the queries and documents into embeddings.\n",
    "#\n",
    "# You can replace 'intfloat/e5-large-v2' with any other model supported by SentenceTransformers.\n",
    "# For example: 'intfloat/e5-large-v2', 'Linq-AI-Research/Linq-Embed-Mistral', etc.\n",
    "encoder_model = SentenceTransformerEncoder(\n",
    "    #model_name_or_path='intfloat/e5-large-v2',\n",
    "    model_name_or_path='/home/ec2-user/FinanceRAG/notebook/fine_tuned_sentence_transformer_e5-large-v2_valanced/',\n",
    "    query_prompt='query: ',\n",
    "    doc_prompt='passage: ',\n",
    ")\n",
    "\"\"\"\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "encoder_model = SentenceTransformerEncoder(\n",
    "    model_name_or_path='Linq-AI-Research/Linq-Embed-Mistral',\n",
    "    #model_name_or_path='ProsusAI/finbert',\n",
    "    query_prompt='query: ',\n",
    "    #query_prompt = \"financial question about the company's financial status: \",\n",
    "    doc_prompt='passage: ',\n",
    "    #doc_prompt = 'inquiry about financial metrics and performance: '\n",
    ")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Initialize CrossEncoder Reranker\n",
    "# --------------------------------------\n",
    "# The CrossEncoder model will be used to rerank the retrieved documents based on relevance.\n",
    "#\n",
    "# You can replace 'cross-encoder/ms-marco-MiniLM-L-12-v2' with any other model supported by CrossEncoder.\n",
    "# For example: 'cross-encoder/ms-marco-TinyBERT-L-2', 'cross-encoder/stsb-roberta-large', etc.\n",
    "reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "    #model=CrossEncoder('cross-encoder/stsb-roberta-large')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running task: FinDER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.common.loader:Loaded 13867 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'ADBE20230004', 'title': 'ADBE OVERVIEW', 'text': 'Adobe is a global technology company with a mission to change the world through personalized digital experiences. For over four decades, Adobe’s innovations have transformed how individuals, teams, businesses, enterprises, institutions, and governments engage and interact across all types of media. Our products, services and solutions are used around the world to imagine, create, manage, deliver, measure, optimize and engage with content across surfaces and fuel digital experiences. We have a diverse user base that includes consumers, communicators, creative professionals, developers, students, small and medium businesses and enterprises. We are also empowering creators by putting the power of artificial intelligence (“AI”) in their hands, and doing so in ways we believe are responsible. Our products and services help unleash creativity, accelerate document productivity and power businesses in a digital world.'}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 216 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'q00001', 'text': 'What are the service and product offerings from Microsoft'}\n",
      "INFO:financerag.retrieval.dense:Encoding queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879a8f840702481fa53c4c6c18b3ed0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2075180037444384d80c070ca26c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved results for 216 queries for FinDER. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q00001\n",
      "  Document 1: Document ID = JNJ20232101, Score = 0.9447249174118042\n",
      "  Document 2: Document ID = JNJ20230392, Score = 0.9394426345825195\n",
      "  Document 3: Document ID = JNJ20230894, Score = 0.9382066130638123\n",
      "  Document 4: Document ID = JNJ20232185, Score = 0.9378847479820251\n",
      "  Document 5: Document ID = JNJ20232340, Score = 0.936808705329895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f652457d1134f52a12aa3105fca9a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.tasks.BaseTask:Output directory set to: ./results/2024-11-09-09/FinDER/FinDER\n",
      "INFO:financerag.tasks.BaseTask:Saving top 10 results to CSV file: ./results/2024-11-09-09/FinDER/FinDER/results.csv\n",
      "INFO:financerag.tasks.BaseTask:Writing header ['query_id', 'corpus_id'] to CSV.\n",
      "INFO:financerag.tasks.BaseTask:Top 10 results saved successfully to ./results/2024-11-09-09/FinDER/FinDER/results.csv\n",
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking results for 216 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q00001\n",
      "  Document 1: Document ID = MSFT20230512, Score = -8.349985122680664\n",
      "  Document 2: Document ID = ADBE20230484, Score = -10.789011001586914\n",
      "  Document 3: Document ID = JNJ20230926, Score = -11.020696640014648\n",
      "  Document 4: Document ID = JNJ20230404, Score = -11.096385955810547\n",
      "  Document 5: Document ID = JNJ20232175, Score = -11.107455253601074\n",
      "Results have been saved to ./results/2024-11-09-09/FinDER/results.csv\n",
      "Running task: FinQABench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.common.loader:Loaded 92 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'd4aa0660c', 'title': '', 'text': 'Apple Inc.\\nCONSOLIDATED STATEMENTS OF OPERATIONS\\n(In millions, except number of shares which are reflected in thousands and per share amounts)\\nYears ended\\nSeptember 24,\\n2022September 25,\\n2021September 26,\\n2020\\nNet sales:\\n   Products $ 316,199 $ 297,392 $ 220,747 \\n   Services  78,129  68,425  53,768 \\nTotal net sales  394,328  365,817  274,515 \\nCost of sales:\\n   Products  201,471  192,266  151,286 \\n   Services  22,075  20,715  18,273 \\nTotal cost of sales  223,546  212,981  169,559 \\nGross margin  170,782  152,836  104,956 \\nOperating expenses:\\nResearch and development  26,251  21,914  18,752 \\nSelling, general and administrative  25,094  21,973  19,916 \\nTotal operating expenses  51,345  43,887  38,668 \\nOperating income  119,437  108,949  66,288 \\nOther income/(expense), net  (334)  258  803 \\nIncome before provision for income taxes  119,103  109,207  67,091 \\nProvision for income taxes  19,300  14,527  9,680 \\nNet income $ 99,803 $ 94,680 $ 57,411 \\nEarnings per share:\\nBasic $ 6.15 $ 5.67 $ 3.31 \\nDiluted $ 6.11 $ 5.61 $ 3.28 \\nShares used in computing earnings per share:\\nBasic  16,215,963  16,701,272  17,352,119 \\nDiluted  16,325,819  16,864,919  17,528,214 \\nSee accompanying Notes to Consolidated Financial Statements.\\nApple Inc. | 2022  Form 10-K | 29'}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 100 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'q4aa0b116', 'text': 'What is the redemption price for the 0.875% 2025 Notes and the 1.375% 2029 Notes if they are redeemed prior to the applicable Par Call Date?'}\n",
      "INFO:financerag.retrieval.dense:Encoding queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d749835b1fac46debc066f5dd388c8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23615033398446f29cff875c2d6df9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved results for 100 queries for FinQABench. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q4aa0b116\n",
      "  Document 1: Document ID = d4aa10922, Score = 0.012769793160259724\n",
      "  Document 2: Document ID = d4aa05798, Score = 0.0027122662868350744\n",
      "  Document 3: Document ID = d4aa0a52c, Score = 0.0026893301401287317\n",
      "  Document 4: Document ID = d4a9ffd70, Score = 0.0025680395774543285\n",
      "  Document 5: Document ID = d4aa0985c, Score = 0.0025219961535185575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d22eb45b684cdba63ac48984adb373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.tasks.BaseTask:Output directory set to: ./results/2024-11-09-09/FinQABench/FinQABench\n",
      "INFO:financerag.tasks.BaseTask:Saving top 10 results to CSV file: ./results/2024-11-09-09/FinQABench/FinQABench/results.csv\n",
      "INFO:financerag.tasks.BaseTask:Writing header ['query_id', 'corpus_id'] to CSV.\n",
      "INFO:financerag.tasks.BaseTask:Top 10 results saved successfully to ./results/2024-11-09-09/FinQABench/FinQABench/results.csv\n",
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n",
      "INFO:financerag.common.loader:Loaded 180 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'dd2af2336', 'title': 'PEPSICO_2022_10K', 'text': '6) Africa, Middle East and South Asia (AMESA), which includes all of our beverage and convenient food businesses in\\nAfrica, the Middle East and South Asia; and\\n7) Asia Pacific, Australia and New Zealand and China Region (APAC), which includes all of our beverage and convenient\\nfood businesses in Asia Pacific, Australia and New Zealand, and China region.'}\n",
      "INFO:financerag.common.loader:Loading Queries...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking results for 100 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q4aa0b116\n",
      "  Document 1: Document ID = d4aa0b1f2, Score = 7.899673938751221\n",
      "  Document 2: Document ID = d4aa0a52c, Score = 5.015963554382324\n",
      "  Document 3: Document ID = d4aa0a7d4, Score = 4.912598609924316\n",
      "  Document 4: Document ID = d4aa10314, Score = 4.468316555023193\n",
      "  Document 5: Document ID = d4aa0a9e6, Score = 4.2903971672058105\n",
      "Results have been saved to ./results/2024-11-09-09/FinQABench/results.csv\n",
      "Running task: FinanceBench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.common.loader:Loaded 150 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'qd2ac917a', 'text': 'What is the FY2019 - FY2020 total revenue growth rate for Block (formerly known as Square)? Answer in units of percents and round to one decimal place. Approach the question asked by assuming the standpoint of an investment banking analyst who only has access to the statement of income.'}\n",
      "INFO:financerag.retrieval.dense:Encoding queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc6bdab4a3849e6bacf5a24dc312d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c75408991ad4778bddad975a2ea659a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved results for 150 queries for FinanceBench. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: qd2ac917a\n",
      "  Document 1: Document ID = dd2acf5c0, Score = 0.014626741409301758\n",
      "  Document 2: Document ID = dd2acf638, Score = 0.013571225106716156\n",
      "  Document 3: Document ID = dd2acf912, Score = 0.013375810347497463\n",
      "  Document 4: Document ID = dd2ac1222, Score = 0.012981723994016647\n",
      "  Document 5: Document ID = dd2acf692, Score = 0.012376612983644009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a310a06ae2dc4d0f9a8f6ff5bce1ddb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.tasks.BaseTask:Output directory set to: ./results/2024-11-09-09/FinanceBench/FinanceBench\n",
      "INFO:financerag.tasks.BaseTask:Saving top 10 results to CSV file: ./results/2024-11-09-09/FinanceBench/FinanceBench/results.csv\n",
      "INFO:financerag.tasks.BaseTask:Writing header ['query_id', 'corpus_id'] to CSV.\n",
      "INFO:financerag.tasks.BaseTask:Top 10 results saved successfully to ./results/2024-11-09-09/FinanceBench/FinanceBench/results.csv\n",
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking results for 150 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: qd2ac917a\n",
      "  Document 1: Document ID = dd2acce74, Score = -0.29550787806510925\n",
      "  Document 2: Document ID = dd2ac8f0e, Score = -2.4054250717163086\n",
      "  Document 3: Document ID = dd2ac285c, Score = -5.096299648284912\n",
      "  Document 4: Document ID = dd2ac8626, Score = -5.100713729858398\n",
      "  Document 5: Document ID = dd2abf562, Score = -6.20806884765625\n",
      "Results have been saved to ./results/2024-11-09-09/FinanceBench/results.csv\n",
      "Running task: TATQA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.common.loader:Loaded 2756 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'd1b2e74c0', 'title': '', 'text': 'The following tables present the recorded investment by portfolio segment and by class, excluding commercial financing receivables and other miscellaneous financing receivables at December 31, 2019 and 2018. Commercial financing receivables are excluded from the presentation of financing receivables by portfolio segment, as they are short term in nature and the current estimated risk of loss and resulting impact to the company’s financing results are not material.\\nWrite-offs of lease receivables and loan receivables were $16 million and $47 million, respectively, for the year ended December 31, 2019. Provisions for credit losses recorded for lease receivables and loan receivables were a release of $6 million and an addition of $2 million, respectively, for the year ended December 31, 2019.\\nThe average recorded investment of impaired leases and loans for Americas, EMEA and Asia Pacific was $138 million, $49 million and $45 million, respectively, for the year ended December 31, 2019. Both interest income recognized, and interest income recognized on a cash basis on impaired leases and loans were immaterial for the year ended December 31, 2019.\\n\\n($ in millions)                                            |          |        |              |         \\n---------------------------------------------------------- | -------- | ------ | ------------ | --------\\nAt December 31, 2019:                                      | Americas | EMEA   | Asia Pacific | Total   \\nRecorded investment:                                       |          |        |              |         \\nLease receivables                                          | $ 3,419  | $1,186 | $  963       | $ 5,567 \\nLoan receivables                                           | 6,726    | 3,901  | 2,395        | 13,022  \\nEnding balance                                             | $10,144  | $5,087 | $3,359       | $18,590 \\nRecorded investment, collectively evaluated for impairment | $10,032  | $5,040 | $3,326       | $18,399 \\nRecorded investment, individually evaluated for impairment | $   112  | $   47 | $   32       | $   191 \\nAllowance for credit losses                                |          |        |              |         \\nBeginning balance at January 1, 2019                       |          |        |              |         \\nLease receivables                                          | $    53  | $   22 | $   24       | $     99\\nLoan receivables                                           | 105      | 43     | 32           | 179     \\nTotal                                                      | $   158  | $   65 | $   56       | $   279 \\nWrite-offs                                                 | (42)     | (3)    | (18)         | (63)    \\nRecoveries                                                 | 1        | 0      | 1            | 2       \\nProvision                                                  | 5        | (7)    | (3)          | (5)     \\nOther*                                                     | (1)      | 0      | (1)          | (2)     \\nEnding balance at December 31, 2019                        | $   120  | $   54 | $   36       | $   210 \\nLease receivables                                          | $    33  | $   23 | $   16       | $    72 \\nLoan receivables                                           | $    88  | $   31 | $   20       | $   138 \\nRelated allowance, collectively evaluated for impairment   | $    25  | $   11 | $    4       | $    39 \\nRelated allowance, individually evaluated for impairment   | $    96  | $   43 | $   32       | $   171 '}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 1663 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'q1a73c1d4', 'text': 'In which year was interest income greater than 7,000 thousands?'}\n",
      "INFO:financerag.retrieval.dense:Encoding queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b134369fd749aebeb27868610f2731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6500d6d162c409eb73ddb886f3c6c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved results for 1663 queries for TATQA. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q1a73c1d4\n",
      "  Document 1: Document ID = d1a71726c, Score = -0.013570000417530537\n",
      "  Document 2: Document ID = d1a735c44, Score = -0.013681773096323013\n",
      "  Document 3: Document ID = d1b39b600, Score = -0.013695847243070602\n",
      "  Document 4: Document ID = d1b355fa6, Score = -0.013698129914700985\n",
      "  Document 5: Document ID = d1b350d80, Score = -0.013710126280784607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58be44bf2fd249e9b26ffa473a216074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2599 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yyyy_mm_dd = datetime.datetime.now().strftime(\"%Y-%m-%d-%H\")\n",
    "output_dir = './results/'+yyyy_mm_dd\n",
    "# make folder if not exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Step 2: Initialize Multiple Tasks and Perform Steps 4-7\n",
    "# -------------------------------------------------------\n",
    "tasks = [FinDER, FinQABench, FinanceBench, TATQA, FinQA, ConvFinQA, MultiHiertt]\n",
    "\n",
    "for task in tasks:\n",
    "    task_name = task.__name__  # Get the name of the task\n",
    "    print(f\"Running task: {task_name}\")\n",
    "    \n",
    "    # Step 2: Initialize the task\n",
    "    finder_task = task()\n",
    "\n",
    "    # Step 4: Perform retrieval\n",
    "    retrieval_model = DenseRetrieval(\n",
    "        model=encoder_model  # Ensure that encoder_model is defined earlier in the notebook\n",
    "    )\n",
    "\n",
    "    retrieval_result = finder_task.retrieve(\n",
    "        retriever=retrieval_model\n",
    "    )\n",
    "\n",
    "    print(f\"Retrieved results for {len(retrieval_result)} queries for {task_name}. Here's an example of the top 5 documents for the first query:\")\n",
    "    for q_id, result in retrieval_result.items():\n",
    "        print(f\"\\nQuery ID: {q_id}\")\n",
    "        sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "        for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "            print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "        break  # Only show the first query\n",
    "\n",
    "    # Step 6: Perform reranking\n",
    "    # -------------------------\n",
    "    # Rerank the top 100 retrieved documents using the CrossEncoder model.\n",
    "    reranking_result = finder_task.rerank(\n",
    "        reranker=reranker,\n",
    "        results=retrieval_result,\n",
    "        top_k=100,  # Rerank the top 100 documents\n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "    # Print a portion of the reranking results to verify the output.\n",
    "    print(f\"Reranking results for {len(reranking_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "    for q_id, result in reranking_result.items():\n",
    "        print(f\"\\nQuery ID: {q_id}\")\n",
    "        # Sort the result to print the top 5 document ID and its score\n",
    "        sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "            print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "        break  # Only show the first query\n",
    "\n",
    "\n",
    "    # Step 7: Save results with the task-specific name\n",
    "    # ------------------------------------------------ \n",
    "    task_output_dir = os.path.join(output_dir, task_name)\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(task_output_dir, exist_ok=True)\n",
    "\n",
    "    # Save the results with the task-specific filename\n",
    "    finder_task.save_results(output_dir=task_output_dir)\n",
    "\n",
    "    # Confirm the results have been saved with the correct task name\n",
    "    print(f\"Results have been saved to {task_output_dir}/results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank the top 100 retrieved documents using the CrossEncoder model.\n",
    "reranking_result = finder_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=retrieval_result,\n",
    "    top_k=100,  # Rerank the top 100 documents\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all results\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob(output_dir + \"/*/*/results.csv\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame.columns = ['query_id', 'corpus_id']\n",
    "frame.to_csv(output_dir + \"/all_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　Read the ground truth file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
